<h2>Research Methods and Professional Practice July 2025 B - Reflection</h2>

<p>Throughout this module I have developed a more structured and critical understanding of research methods, data analysis, and the application of statistical techniques to real-world problems. The progression from the literature review and research proposal to the practical case studies and hypothesis testing exercises has allowed me to integrate theoretical knowledge with technical skills. This reflection brings together my learning experiences and discusses how they have contributed to my academic development and my broader professional growth.</p>

<p>The literature review was the foundation of this journey. At first, it was a challenge to navigate a wide range of academic sources and synthesize them into a coherent narrative. The topic I selected required identifying key debates, assessing the reliability of different types of evidence, and situating my research question within an existing body of work. This process taught me how to evaluate credibility and bias, and how to construct a logical argument supported by literature rather than opinion. I began to appreciate the importance of critical appraisal and the need to distinguish between correlation and causation when interpreting empirical findings. The feedback I received encouraged me to sharpen my focus and ensure that every reference directly supported my argument. That exercise strengthened my academic writing skills and gave me a framework for evaluating the quality and purpose of research design.</p>

<p>Developing the research proposal built directly on the literature review. It was no longer about summarizing knowledge but about applying it to design a feasible and ethical study. I learned how to identify variables, formulate hypotheses, and choose methods that align with the research objectives. Constructing the proposal required me to think about sampling, measurement validity, and potential limitations in advance. I also learned the value of transparency in research design. For example, I realized that explaining why a particular methodology is chosen is as important as the method itself. Ethical considerations became much more concrete during this stage. Questions of participant consent, confidentiality, and data protection were not abstract principles but essential components that would determine the credibility of any study. This process taught me that sound research is as much about integrity and responsibility as it is about technical skill.</p>

<p>The statistical exercises provided an opportunity to apply theory to data-driven practice. Working through the hypothesis testing exercises helped me understand how to move from descriptive summaries to inferential conclusions. Initially, terms like t-tests, F-tests, and p-values felt procedural. However, through repetition and interpretation I began to see them as tools for making evidence-based decisions. For example, in the exercise comparing two diets, the difference in means and variances was not just a mathematical output but a practical way to assess whether one treatment was genuinely more effective. Similarly, in the paired-sample container design exercise, calculating the correlation and t statistic helped illustrate how controlled comparisons can detect meaningful differences between conditions. I learned that statistical significance must always be interpreted in context and that a small p-value is not meaningful without understanding the underlying assumptions and practical implications.</p>

<p>The case studies and discussions encouraged me to reflect on the ethical and professional dimensions of research and computing. The Cambridge Analytica example highlighted how data collection can be manipulated for unintended and unethical purposes. It reminded me that analytical skill must be accompanied by ethical awareness. Similarly, the case involving the statistical programmer Abi challenged me to consider integrity in data analysis. Even if data are technically correct, selective presentation or manipulation of analyses can mislead decision makers. These cases connected directly to the professional codes of conduct from organizations such as the ACM and BCS. They reinforced the principle that computing professionals have a duty to uphold honesty, fairness, and accountability in all aspects of their work. I learned that ethical issues often arise not from ignorance but from pressure to satisfy external interests, and that professional responsibility requires courage to resist such pressures.</p>

<p>Reflecting on these tasks as a whole, I have noticed growth in several key areas. My statistical analysis skills have become more confident and precise. I can now interpret test results rather than simply compute them, understanding what they imply for real-world decisions. I have developed a stronger ability to question assumptions, whether about normality, independence, or equality of variance, and to appreciate how these assumptions shape the validity of a test. This awareness will guide me in evaluating the robustness of future research I encounter in my professional work. I have also improved in communicating results clearly and concisely, translating numerical evidence into reasoned conclusions.</p>

<p>In terms of the research methods process, I have learned the importance of structure and replication. Every stage of research, from defining a problem to analyzing data, builds upon the previous one. A flawed design cannot be fixed by sophisticated analysis, and a well-designed study loses credibility without transparent reporting. The exercises and case studies showed me how theory, method, and ethics must align for research to be meaningful. I now view research as a systematic but creative process that requires both technical discipline and the curiosity to ask the right questions.</p>

<p>From a personal and professional perspective, this module has had a strong impact on how I approach problem solving. Professionally, I have gained skills that are directly relevant to my work in data analysis and decision support. I am more comfortable using statistical reasoning to evaluate evidence and to challenge conclusions that lack empirical support. Personally, I have developed patience and persistence. Many of the exercises required careful checking of calculations and interpretation. Early mistakes taught me that accuracy comes from attention to detail and iterative verification. The skills I practiced here, including critical thinking, data integrity, and ethical awareness, are transferable to any setting where information guides decisions.</p>
